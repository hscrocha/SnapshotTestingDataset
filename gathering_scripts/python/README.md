# SnapShot Testing Collection Python Script

## Scripts:
1. GetReposJestToCSV.py
2. FullInfo.py
3. TestFileCounter.py

## You will Need:
Python, git installed, Github Packages for Python (github, pygithub), a Github token (https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token), and GitTrends Proxy Server (https://github.com/gittrends-app/github-proxy-server).

## Intructions

Make sure the Proxy Server is running (that is a coded by another researcher), or make necessary adjustments to URL to not use the proxy server (although we strongly recommend using the proxy server). In all scripts you need to add your GitHub Token into the token in the marked places. There are three scripts, and each one plays its role for collecting data (best used in order).
1. GetReposJestToCSV.py is the first script to run, it fetches the repositories by query from Github itself and saves it to a CSV along with some basic information.
2. Because we wanted to be open to extensions on the attributes we were gathering, FullInfo.py reads the Github URL from the spreadsheet generated by GetReposJestToCSV.py and obtains the attributes from there. Splitting up the process allowed us to finalize which attributes we were looking for and how to formulate it on the spreadsheet. 
3. We later decided to include the number of both test and snapshot files. TestFileCounter.py retrieves the number of snapshot or general test files depending on which query you use and appends it to a spreadsheet of your choice. 

### GetReposJestToCSV.py:

Takes a query and segments it by star increments to bypass the API limit. Records basic information about a repo, checks whether .snap files exist in the repos, and records relevant information into a spreadsheet for later use

Notes on GetReposJestToCSV.py:
- Since there are many attributes of the queries used, it was faster to hardcode them into the program itself instead of inputting values at every run. 
- Additionally, as to not overflow past the API limit, the query has to be further broken down by star count increments. Repositories are added in increments of 0-10 stars, 10-100 stars, 1000-10000 stars, so on. The incrementation also makes the hardcoded option easier, as we could edit the starting increments depending on how much of the data we needed if we wanted to obtain part of the dataset. 

Queries Used:
- 'language:javascript topic:jest sort:stars-desc stars:{}..{}'.format(loopend,loopstart)
- 'language:TypeScript topic:jest sort:stars-desc stars:{}..{}'.format(loopend,loopstart)

### FullInfo.py:

Using the information provided by the the spreadsheet generated from GetReposJestToCSV.py, FullInfo.py takes the GitHub URL provided and retrieves the necessary attributes from each repo and outputs it into a spreadsheet

Notes on FullInfo.py:

- The attributes are hardcoded, since there are too many attributes recorded to manually input efficiently each time, and the list of attributes we would include were not yet finalized. 


### TestFileCounter.py:

 TestFileCounter.py retrieves the number of snapshot or general test files depending on which query you use and appends it to a spreadsheet of your choice. 

 Queries:
 - "filename:test repo:{}".format(text) - if looking for the number of general test files
 - "extension:snap repo:{}".format(text) - if looking for number of .snap test files specifically
 
 ##  Example Run:

Script: GetReposJestToCSV.py
Output: yourOutputFile.csv 
 To simplify this example to run the script, instead of looking for all repositories, change the query (line 58) to `user:hscrocha language:java sort:stars-desc stars:{}..{}`
 to narrow down our search for repos by user hscrocha (the second author) written in Java, instead of all repositories written in Javascript with a jest topic.

 Since we changed the query to Java for this example, we also need to change the languages in lines 89 and 92 to reflect the Java language.

 Note: Line 112 stops the program so that only repositories that have more than 1 star are written to the CSV. Because this is not necessary for this example, change if loopend == 1 to if loopend == 0

 Results: Obtained 5/5 results sorted in order of stars, saved into CSV along with language, star count, and whether or not the repo contains a snap file.


Script: FullInfo.py
Output: yourOutputFileFull.csv

The program takes all of the repositories gathered by the first script, and obtains important attributes about them. Here, the program looks for "Name", 'Star Count', 'Size', 'Fork #', 'Watchers #', 'Created','Updated','Organization','Subscribers','Issues', and 'Networks'

Results: obtained important attributes for each of the repositories found in the previous script, and saved it to a different CSV

 Script: TestFileCounter.py
 Output: countingFile.csv

The program takes all of the repositories gathered by the first script, and counts either general test files, or snapshot testing files, depending what is specified in the code. For this example, I chose to count general testing files. 

Results: obtained a .CSV with the names of the 5 repos found in the first script, along with a count of how many general test files are in that repository. 
